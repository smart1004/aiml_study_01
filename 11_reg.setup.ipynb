{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reg1 = reg.setup(data = boston, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[reg.setup](https://pycaret.org/setup/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initializing the setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step 2: Initializing the setup\n",
    "\n",
    "Common to all modules in PyCaret, setup is the first and the only mandatory step to start any machine learning experiment. \n",
    "PyCaret의 모든 모듈에 공통적으로 적용되며, 설정은 기계 학습 실험을 시작하기 위한 첫 번째 및 유일한 필수 단계다. \n",
    "\n",
    "Besides performing some basic processing tasks by default, PyCaret also offers wide array of pre-processing features \n",
    "which structurally elevates an average machine learning experiment to an advanced solution. \n",
    "PyCaret은 기본 처리 작업을 기본적으로 수행하는 것 외에도 구조적으로 \n",
    "일반적인 기계 학습 실험을 고급 솔루션으로 끌어올리는 광범위한 사전 처리 기능도 제공한다. \n",
    "\n",
    "\n",
    "We have only covered the essential part of the setup function in this section. \n",
    "우리는 이 절에서 설정 기능의 필수적인 부분만 다루었다. \n",
    "\n",
    "Elaborate details of all the pre-processing features can be found here. \n",
    "모든 전처리 기능에 대한 자세한 내용은 여기에서 확인할 수 있다.\n",
    "\n",
    "Listed below are the essential default tasks performed by PyCaret when you initialize the setup:    \n",
    "아래 목록은 설정을 초기화할 때 PyCaret에서 수행하는 필수 기본 작업이다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type Inference:  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Any experiment performed in PyCaret begins with determining the correct data types for all features. \n",
    "PyCaret에서 수행되는 모든 실험은 모든 피처에 대한 정확한 데이터타입을 결정하는 것으로 시작한다. \n",
    "\n",
    "The setup function performs essential inferences about the data and performs several downstream tasks such as ignoring ID and Date columns,\n",
    "categorical encoding, missing values imputation based on the data type inferred by PyCaret’s internal algorithm. \n",
    "\n",
    "설정 기능은 데이터에 대한 기본적인 추론을 수행하고 ID 및 Date 칼럼 무시와 같은 여러 다운스트림 작업을 수행한다.\n",
    "PyCaret의 내부 알고리즘에 의해 추론된 결과에 따라 범주형 인코딩, 데이터 타입 기반 결측치 대치 작업을 수행한다.\n",
    "\n",
    "Once the setup is executed a dialogue box (see example below) appears with the list of all the features and their inferred data types. \n",
    "설정이 실행되면 모든 피처의 추론된 데이터타입 목록이 나타납니다. \n",
    "\n",
    "Data type inferences are usually correct but once the dialogue box appears, user should review the list for accuracy. \n",
    "데이터 타입 추론은 보통 정확하지만 대화 상자가 나타나면 사용자가 목록을 검토하여 정확성을 확인해야합니다.\n",
    "\n",
    "If all the data types are inferred correctly you may press enter to continue or if not you may type ‘quit‘ to stop the experiment.\n",
    "모든 데이터타입이 올바르게 추론된 경우 Enter 키를 눌러 계속하거나, 'quit'를 입력하여 실험을 중지 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저걸setup 실행 결과  데이터타입이 맞으면  Enter 키를 눌러 계속\n",
    "### 그렇지 않으면  type ‘quit‘ to stop the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If you choose to enter ‘quit‘ because one or more data types were not inferred correctly, \n",
    "you can overwrite them within setup command by passing categorical_feature parameter to force categorical \n",
    "type and numeric_feature parameter to force numeric type. \n",
    "\n",
    "Similarly,in order to ignore certain features to become part of experiment you can pass ignore_features parameter within setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나 이상의 데이터 유형이 올바르게 추론되지 않았기 때문에  'quit' 를 입력하기로 선택한 경우 categorical_feature 매개 변수를 전달 하여 \n",
    "범주 유형을 강제하고 numeric_feature 매개 변수를 전달하여 숫자 유형을 강제 적용 하여 설정 명령 내에서 이를 덮어 쓸 수 있습니다 . \n",
    "마찬가지로 실험의 일부가 되기 위해 특정 기능을 무시하려면 설정 내에서 ignore_features 매개 변수를 전달할 수 있습니다 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you don’t want PyCaret to display the dialogue for confirmation of data types you may pass silent as True within setup \n",
    "to perform a unattended run of experiment. \n",
    "\n",
    "We don’t recommend that unless you are absolutely sure the inference \n",
    "is correct or you have performed the experiment before or you are overwriting data types using numeric_feature and categorical_feature parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : PyCaret이 데이터 유형 확인을 위한 대화 상자를 표시하지 않도록 하려면 설정 내에서 True 로 무인 상태 로 전달 하여 \n",
    "무인 실험 실행을 수행 할 수 있습니다. \n",
    "추론이 정확한지 절대적으로 확신하지 않거나 이전에 실험을 수행했거나 numeric_feature 및 categorical_feature 매개 변수를 사용하여 \n",
    "데이터 유형을 덮어 쓰지 않는 한 권장하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Cleaning and Preparation: \n",
    "setup function automatically performs missing value imputation and \n",
    "categorical encoding as they are imperative for any machine learning experiment. \n",
    "\n",
    "By default mean value is used for imputation of numeric features and most frequent value or mode is used for categorical features. \n",
    "You may change the method using numeric_imputation and categorical_imputation parameter. \n",
    "For classification problems, setup also performs target encoding if target is not of type numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "■ 데이터 정리 및 준비 :  \n",
    "설정 기능은 모든 기계 학습 실험에 필수적인 결측값 대치 및 범주 인코딩을 자동으로 수행합니다. \n",
    "기본적으로 평균 값은 숫자피처의 대치에 사용되며 최빈값은 범주형 피처에 사용됩니다. \n",
    "numeric_imputation 및 categorical_imputation 매개 변수를 사용하여 방법을 변경할 수 있습니다 . \n",
    "\n",
    "분류 문제의 경우 타겟(종속변수)이 숫자형이 아닌 경우 셋업펑션은 타겟인코딩도 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Sampling: \n",
    "If the sample size is greater than 25,000, PyCaret automatically builds a preliminary linear model based on different sample sizes \n",
    "and provides a visual that shows the performance of the model based on sample size. \n",
    "his plot can then be used to evaluate if the performance of model increases with increase in sample size. \n",
    "If not, you may choose a smaller sample size in interest of efficiency and performance of the experiment. \n",
    "See an example below where we have used the ‘bank‘ dataset from pycaret’s repository and it has 45,211 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "데이터 샘플링 : \n",
    "샘플 크기가 25,000보다 큰 경우 PyCaret은 다양한 샘플 크기를 기반으로 예비 선형 모델을 자동으로 구축하고 샘플 크기에 따라 모델의 성능을 \n",
    "보여주는 시각적 개체를 제공합니다. \n",
    "그런 다음이 플롯을 사용하여 표본 크기가 증가함에 따라 모델의 성능이 향상되는지 평가할 수 있습니다. \n",
    "\n",
    "그렇지 않은 경우 실험의 효율성과 성능을 위해 더 작은 샘플 크기를 선택할 수 있습니다. \n",
    "pycaret의 저장소에서 'bank'데이터 세트를 사용했으며 45,211 개의 샘플이 있는 아래 예를 참조하세요 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train Test Split: \n",
    "    setup function also performs the train test split (stratified for classification problems). \n",
    "The default split ratio is 70:30 but you can change that using train_size parameter within setup. \n",
    "Evaluation of a trained machine learning model and hyperparameter optimization in PyCaret is performed using k-fold cross validation on \n",
    "Train set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "트레인 테스트 분할 : \n",
    "    설정 기능은 트레인 테스트 분할도 수행합니다 (분류 문제를 위해 계층화 됨). \n",
    "기본 분할 비율은 70:30이지만 설정 내에서 train_size 매개 변수 를 사용하여 변경할 수 있습니다 . \n",
    "훈련 된 기계 학습 모델의 평가와 PyCaret의 하이퍼 파라미터 최적화는 훈련 세트 에서만 k- 겹 교차 검증을 사용하여 수행  됩니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assigning Session ID as seed: \n",
    "    session id is a pseudo random number generated by default if no session_id parameter is passed. \n",
    "PyCaret distributes this id as a seed in all the functions to isolate the effect of randomization. \n",
    "This allows for reproducibility at later date in the same or different environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "세션 ID를 시드로 지정 : \n",
    "    세션 ID는 session_id 매개 변수가 전달 되지 않은 경우 기본적으로 생성되는 의사 난수 입니다. \n",
    "PyCaret은이 id를 모든 기능의 시드로 배포하여 무작위화 효과를 분리합니다. \n",
    "이는 나중에 동일하거나 다른 환경에서 재현성을 허용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_conda3",
   "language": "python",
   "name": "py38_conda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
